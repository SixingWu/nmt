python3 -m nrm.nrm      --num_units=240      --out_dir=models/chinese_char_lstm      --infer_batch_size=10      --num_layers=2      --test_prefix=/ldev/tensorflow/nmt2/nmt/data/charspace/test      --metrics=rouge@space,bleu-1@space,bleu-2@space,bleu-3@space,bleu-4@space,distinct-1@space,distinct-2@space      --src_max_len=50      --tgt=response      --unit_type=lstm      --train_prefix=/ldev/tensorflow/nmt2/nmt/data/charspace/train      --dev_prefix=/ldev/tensorflow/nmt2/nmt/data/charspace/dev      --batch_size=64      --share_vocab=False      --encoder_type=bi      --num_train_steps=1000000      --attention=luong      --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/charspace/vocab.40000.separate      --steps_per_stats=100      --tgt_max_len=50      --src=message      --embed_dim=320     >> logs/chinese_char_lstm.txt 

python3 -m nrm.nrm  --infer_beam_width=10 --out_dir=models/chinese_char_lstm --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/charspace/vocab.40000.separate --inference_input_file=/ldev/tensorflow/nmt2/nmt/data/charspace/test.message --inference_output_file=infer_test/chinese_char_lstm.test.txt >> infer_test/log/chinese_char_lstm.test.txt
    
python3 -m nrm.utils.evaluation_utils chinese_char_lstm /ldev/tensorflow/nmt2/nmt/data/charspace/test.response infer_test/chinese_char_lstm.test.txt infer_test/scores/chinese_char_lstm.test.txt rouge@space,bleu-1@space,bleu-2@space,bleu-3@space,bleu-4@space,distinct-1@space,distinct-2@space
    
