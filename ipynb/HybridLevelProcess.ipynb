{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取所有Chracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6688\n",
      "120929\n",
      "10549\n",
      "618079\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "in_path = '/ldev/tensorflow/nmt2/nmt/data/wordlevel/'\n",
    "\n",
    "words_dict = {}\n",
    "chars_dict = {}\n",
    "for file in ['message','response']:\n",
    "    characters = defaultdict(int)\n",
    "    words = defaultdict(int)\n",
    "    with open(in_path+'train.'+file,'r',encoding='utf-8') as fin:\n",
    "        for line in fin.readlines():\n",
    "            tokens = line.strip('\\n').split()\n",
    "            for token in tokens:\n",
    "                words[token] += 1\n",
    "                for char in token:\n",
    "                    characters[char] += 1\n",
    "        print(len(characters))\n",
    "        print(len(words))\n",
    "        words_dict[file] = words\n",
    "        chars_dict[file] = characters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写一个程序，控制Character的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "def count(total_count,file,output_id):\n",
    "    words = words_dict[file]\n",
    "    chars = (chars_dict[file].keys())\n",
    "    vocab = set()\n",
    "    sorted_words = sorted(words.items(), key = lambda x:x[1], reverse=True)\n",
    "    for i in range(0,total_count - len(chars)):\n",
    "        vocab.add(sorted_words[i][0])\n",
    "    for i in range(total_count - len(chars)):\n",
    "        for char in sorted_words[i][0]:\n",
    "            vocab.add(char)\n",
    "    with open('/ldev/tensorflow/nmt2/nmt/data/hybridlevel/vocab.'+str(output_id)+'.'+file,'w+',encoding='utf-8') as fout:\n",
    "        fout.write('\\n'.join(list(vocab)))\n",
    "    print(len(vocab))\n",
    "\n",
    "# count(44616,'message',40000)\n",
    "# count(48800,'response',40000)\n",
    "# count(25206,'message',20000)\n",
    "# count(29218,'response',20000)\n",
    "# count(83918,'message',80000)\n",
    "# count(88539,'response',80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取对应的文件，然后生成相应的标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_per_sentence: message 20000\n",
      "2 0.00 3 0.00 4 0.00 5 0.01 6 0.02 7 0.05 8 0.09 9 0.16 10 0.23 11 0.31 12 0.39 13 0.47 14 0.55 15 0.63 16 0.70 17 0.77 18 0.83 19 0.88 20 0.93 21 0.95 22 0.97 23 0.98 24 0.98 25 0.99 26 0.99 27 0.99 28 0.99 29 0.99 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 45 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 53 1.00 54 1.00 56 1.00 57 1.00 \n",
      "items_per_sentence: message 40000\n",
      "2 0.00 3 0.00 4 0.00 5 0.01 6 0.02 7 0.06 8 0.12 9 0.19 10 0.27 11 0.35 12 0.44 13 0.52 14 0.60 15 0.68 16 0.75 17 0.82 18 0.88 19 0.93 20 0.96 21 0.98 22 0.98 23 0.99 24 0.99 25 0.99 26 0.99 27 1.00 28 1.00 29 1.00 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 45 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 55 1.00 57 1.00 \n",
      "items_per_sentence: message 80000\n",
      "2 0.00 3 0.00 4 0.00 5 0.01 6 0.03 7 0.07 8 0.14 9 0.21 10 0.30 11 0.39 12 0.48 13 0.56 14 0.65 15 0.73 16 0.80 17 0.86 18 0.92 19 0.96 20 0.99 21 1.00 22 1.00 23 1.00 24 1.00 25 1.00 26 1.00 27 1.00 28 1.00 29 1.00 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 \n",
      "items_per_sentence: response 20000\n",
      "2 0.00 3 0.00 4 0.00 5 0.02 6 0.08 7 0.18 8 0.30 9 0.42 10 0.52 11 0.60 12 0.67 13 0.73 14 0.79 15 0.83 16 0.87 17 0.90 18 0.93 19 0.95 20 0.97 21 0.98 22 0.99 23 0.99 24 0.99 25 1.00 26 1.00 27 1.00 28 1.00 29 1.00 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 45 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 53 1.00 54 1.00 55 1.00 56 1.00 57 1.00 58 1.00 59 1.00 60 1.00 61 1.00 62 1.00 63 1.00 64 1.00 65 1.00 66 1.00 67 1.00 68 1.00 69 1.00 70 1.00 71 1.00 72 1.00 73 1.00 74 1.00 75 1.00 76 1.00 77 1.00 79 1.00 82 1.00 83 1.00 \n",
      "items_per_sentence: response 40000\n",
      "2 0.00 3 0.00 4 0.00 5 0.03 6 0.10 7 0.21 8 0.34 9 0.45 10 0.55 11 0.63 12 0.70 13 0.76 14 0.81 15 0.85 16 0.89 17 0.92 18 0.95 19 0.97 20 0.98 21 0.99 22 0.99 23 0.99 24 1.00 25 1.00 26 1.00 27 1.00 28 1.00 29 1.00 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 45 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 53 1.00 54 1.00 55 1.00 56 1.00 57 1.00 58 1.00 59 1.00 60 1.00 61 1.00 62 1.00 63 1.00 64 1.00 65 1.00 66 1.00 67 1.00 68 1.00 69 1.00 70 1.00 71 1.00 72 1.00 73 1.00 74 1.00 75 1.00 76 1.00 77 1.00 79 1.00 82 1.00 83 1.00 \n",
      "items_per_sentence: response 80000\n",
      "2 0.00 3 0.00 4 0.00 5 0.03 6 0.11 7 0.23 8 0.36 9 0.47 10 0.57 11 0.65 12 0.72 13 0.78 14 0.83 15 0.87 16 0.90 17 0.93 18 0.96 19 0.98 20 0.99 21 0.99 22 1.00 23 1.00 24 1.00 25 1.00 26 1.00 27 1.00 28 1.00 29 1.00 30 1.00 31 1.00 32 1.00 33 1.00 34 1.00 35 1.00 36 1.00 37 1.00 38 1.00 39 1.00 40 1.00 41 1.00 42 1.00 43 1.00 44 1.00 45 1.00 46 1.00 47 1.00 48 1.00 49 1.00 50 1.00 51 1.00 52 1.00 53 1.00 54 1.00 55 1.00 56 1.00 57 1.00 58 1.00 59 1.00 60 1.00 61 1.00 62 1.00 63 1.00 64 1.00 65 1.00 66 1.00 67 1.00 68 1.00 69 1.00 70 1.00 71 1.00 72 1.00 73 1.00 74 1.00 75 1.00 79 1.00 82 1.00 83 1.00 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_path = '/ldev/tensorflow/nmt2/nmt/data/wordlevel/'\n",
    "for file in ['message','response']:\n",
    "    for vocab_size in [20000,40000,80000]:\n",
    "        vocab = set()\n",
    "        with open('/ldev/tensorflow/nmt2/nmt/data/hybridlevel/vocab.'+str(vocab_size)+'.'+file,'r+',encoding='utf-8') as fin:\n",
    "            for line in fin.readlines():\n",
    "                vocab.add(line.strip())\n",
    "        for prefix  in ['train','test','dev']:\n",
    "            sen_len_counter = defaultdict(int)\n",
    "            with open('/ldev/tensorflow/nmt2/nmt/data/hybridlevel/'+prefix+'.'+str(vocab_size)+'.'+file,'w',encoding='utf-8') as fout:\n",
    "                with open(in_path+prefix+'.'+file,'r',encoding='utf-8') as fin:\n",
    "                    total_len = 0\n",
    "                    for line in fin.readlines():\n",
    "                        res = []\n",
    "                        for token in line.strip('\\n').split():\n",
    "                            if token not in vocab:\n",
    "                                res = res + list(token)\n",
    "                            else:\n",
    "                                res.append(token)\n",
    "                        fout.write(' '.join(res)+'\\n')\n",
    "                        sen_len_counter[len(res)] += 1\n",
    "                        total_len += 1\n",
    "            \n",
    "            if prefix == 'train':\n",
    "                print('items_per_sentence: %s %s' % (file,vocab_size))\n",
    "                sorted_length = sorted(sen_len_counter.items(), key = lambda x:x[0])\n",
    "                total_counter = 0\n",
    "                line_str = ''\n",
    "                for lens,counter in sorted_length:\n",
    "                    total_counter += counter\n",
    "                    line_str += '%d %.2f ' % (lens, total_counter/total_len)\n",
    "                print (line_str)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
