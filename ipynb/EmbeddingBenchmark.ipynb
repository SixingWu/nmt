{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word nums : 34837\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ref_file = '/ldev/tensorflow/nmt2/nmt/data/wordlevel/test.40000.response'\n",
    "embed_file = '/ldev/tensorflow/nmt2/word_embed/wiki.zh.vec'\n",
    "eval_files = [\n",
    "    '/ldev/tensorflow/nmt2/nmt/infer_test/cn_albpe2.test.txt',\n",
    "    '/ldev/tensorflow/nmt2/nmt/infer_test/cn_rnn_hlat.test.txt',\n",
    "    '/ldev/tensorflow/nmt2/nmt/infer_test/bpe_lstm.test.txt',\n",
    "    '/ldev/tensorflow/nmt2/nmt/infer_test/cnnencdec.test.txt',\n",
    "    '/ldev/tensorflow/nmt2/nmt/infer_test/chinese_lstm.test.txt',\n",
    "             ]\n",
    "eval_subword = ['hybrid','hybrid','bpe','space',None]\n",
    "\n",
    "# 统计所有用到的词\n",
    "word_dict = set()\n",
    "\n",
    "def encode(sentence, subword_option_1):\n",
    "    sentence = sentence.strip('\\n').lower()\n",
    "    if subword_option_1 == 'bpe':\n",
    "        sentence = re.sub(\"@@ \", \"\", sentence)\n",
    "    if subword_option_1 == 'space':\n",
    "        sentence = sentence.replace(\" \", \"\")\n",
    "        sentence = sentence.replace(\"<space>\",\" \")\n",
    "    if subword_option_1 == 'char':\n",
    "        sentence = sentence.replace(\"<space>\", \"\")\n",
    "        sentence = sentence.replace(\"@@\", \"\")\n",
    "        sentence = sentence.replace(\" \",\"\")\n",
    "        sentence = \" \".join(sentence)\n",
    "    elif subword_option_1 == 'char2char':\n",
    "        sentence = sentence.replace(\" \", \"\")\n",
    "        sentence = sentence.replace(\"@@\", \"\")\n",
    "        sentence = \" \".join(sentence)\n",
    "    elif subword_option_1 == 'char2word':\n",
    "        sentence = sentence.replace(\" \", \"\")\n",
    "        sentence = sentence.replace(\"@@\", \" \")\n",
    "        # sentence = \" \".join(sentence)\n",
    "    elif subword_option_1 == 'hybrid':\n",
    "        sentence = sentence.replace(\" @@ \", \"\")\n",
    "        sentence = sentence.replace(\"@@ \", \"\")\n",
    "        sentence = sentence.replace(\" @@\", \"\")\n",
    "    elif subword_option_1 == 'hybrid2':\n",
    "        sentence = sentence.replace(\" \", \"\")\n",
    "        sentence = sentence.replace(\"@@\", \" \")\n",
    "    return sentence\n",
    "\n",
    "\n",
    "for file,subword in zip(eval_files + [ref_file], eval_subword +[None]):\n",
    "    with open(file, 'r', encoding = 'utf-8') as fin:\n",
    "        for line in fin.readlines():\n",
    "            encoded_line = encode(line,subword)\n",
    "            for word in encoded_line.split(' '):\n",
    "                word_dict.add(word.lower())\n",
    "\n",
    "print('word nums : %d' % (len(word_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(embed_file,encoding='ISO-8859-1') as f:\n",
    "#     with open(embed_file+'.u8','w+',encoding='utf-8') as f2:\n",
    "#         for line in f.readlines():\n",
    "#             try:\n",
    "#                 uft_str = line.encode(\"iso-8859-1\").decode('utf-8') \n",
    "#                 f2.write(uft_str)\n",
    "#             except :\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16377\n"
     ]
    }
   ],
   "source": [
    "# 加载embedding\n",
    "import numpy as np\n",
    "def read_vectors(path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "    lines_num, dim = 0, 0\n",
    "    vectors = {}\n",
    "    iw = []\n",
    "    wi = {}\n",
    "    with open(path,encoding='utf-8') as f:\n",
    "        first_line = True\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                dim = int(line.strip().split()[1])\n",
    "                continue\n",
    "            lines_num += 1\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            if tokens[0] in word_dict:\n",
    "                vectors[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])\n",
    "                vectors[tokens[0]] = vectors[tokens[0]]\n",
    "                iw.append(tokens[0])\n",
    "            if topn != 0 and lines_num >= topn:\n",
    "                break\n",
    "    for i, w in enumerate(iw):\n",
    "        wi[w] = i\n",
    "    return vectors, iw, wi, dim\n",
    "\n",
    "vectors = read_vectors(embed_file,0)\n",
    "print(len(vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embedding AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['，',\n",
       " '的',\n",
       " '。',\n",
       " '-',\n",
       " '年',\n",
       " \"'\",\n",
       " '（',\n",
       " '）',\n",
       " '}',\n",
       " '、',\n",
       " '.',\n",
       " '月',\n",
       " ')',\n",
       " '(',\n",
       " '日',\n",
       " '在',\n",
       " '：',\n",
       " '是',\n",
       " '/',\n",
       " '\"',\n",
       " '和',\n",
       " '#',\n",
       " '》',\n",
       " '《',\n",
       " 'q',\n",
       " '了',\n",
       " '·',\n",
       " '村',\n",
       " '人',\n",
       " '%',\n",
       " '中',\n",
       " '为',\n",
       " '」',\n",
       " '「',\n",
       " '被',\n",
       " '斯',\n",
       " '有',\n",
       " '及',\n",
       " '於',\n",
       " '第',\n",
       " '以',\n",
       " '上',\n",
       " '而',\n",
       " '由',\n",
       " '大',\n",
       " '特',\n",
       " '之',\n",
       " '科',\n",
       " '他',\n",
       " '；',\n",
       " '于',\n",
       " '—',\n",
       " '至',\n",
       " '地',\n",
       " '德',\n",
       " '等',\n",
       " '重',\n",
       " '一',\n",
       " '一个',\n",
       " '\\\\',\n",
       " '其',\n",
       " '但',\n",
       " '中国',\n",
       " 'a',\n",
       " '下',\n",
       " 'the',\n",
       " '也',\n",
       " '名',\n",
       " '拉',\n",
       " '到',\n",
       " '留言',\n",
       " '市',\n",
       " '与',\n",
       " '克',\n",
       " '后',\n",
       " '新',\n",
       " 'e',\n",
       " '或',\n",
       " '香港',\n",
       " '站',\n",
       " '州',\n",
       " '研究',\n",
       " '罗',\n",
       " '日本',\n",
       " '者',\n",
       " '三',\n",
       " '县',\n",
       " 'of',\n",
       " '前',\n",
       " '－',\n",
       " '家',\n",
       " '所',\n",
       " '近',\n",
       " '米',\n",
       " '多',\n",
       " '使用',\n",
       " '会',\n",
       " '基',\n",
       " '区',\n",
       " '阿',\n",
       " '王',\n",
       " '可以',\n",
       " '林',\n",
       " '已',\n",
       " '公司',\n",
       " '个',\n",
       " '李',\n",
       " '索',\n",
       " '天',\n",
       " '西',\n",
       " '省',\n",
       " '度',\n",
       " '卡',\n",
       " '并',\n",
       " '该',\n",
       " 'b',\n",
       " '二',\n",
       " '小',\n",
       " '相似',\n",
       " '时',\n",
       " '不',\n",
       " '部',\n",
       " '里',\n",
       " '人口',\n",
       " '四',\n",
       " '政府',\n",
       " '都',\n",
       " '其中',\n",
       " '尼',\n",
       " '？',\n",
       " '这',\n",
       " '我',\n",
       " '道',\n",
       " '利',\n",
       " '+',\n",
       " '又',\n",
       " '分',\n",
       " '对',\n",
       " '高',\n",
       " '因',\n",
       " 's',\n",
       " '集',\n",
       " '布',\n",
       " '以及',\n",
       " '此',\n",
       " '世界',\n",
       " '可',\n",
       " '南',\n",
       " 'c',\n",
       " '小组',\n",
       " '台',\n",
       " '路',\n",
       " '格',\n",
       " '五',\n",
       " 'f',\n",
       " 'style',\n",
       " '本',\n",
       " '用',\n",
       " '就',\n",
       " '总',\n",
       " '镇',\n",
       " '金',\n",
       " '将',\n",
       " '曾',\n",
       " '文',\n",
       " '巴',\n",
       " '子',\n",
       " '号',\n",
       " 'or',\n",
       " '人民',\n",
       " '包括',\n",
       " '安',\n",
       " '峰',\n",
       " '美国',\n",
       " '其他',\n",
       " '出',\n",
       " '次',\n",
       " '塔',\n",
       " '大学',\n",
       " '型',\n",
       " '第一',\n",
       " '任',\n",
       " 'and',\n",
       " '比',\n",
       " '元',\n",
       " '东',\n",
       " 'd',\n",
       " '六',\n",
       " '两',\n",
       " '伊',\n",
       " '?',\n",
       " '主要',\n",
       " '城',\n",
       " '法',\n",
       " '马',\n",
       " '中心',\n",
       " 'seed',\n",
       " 'p',\n",
       " '第二',\n",
       " '山',\n",
       " '加',\n",
       " '太空',\n",
       " '自己',\n",
       " '最',\n",
       " '向',\n",
       " '自',\n",
       " '夫',\n",
       " 'm',\n",
       " '位',\n",
       " '主',\n",
       " '雷',\n",
       " '管理',\n",
       " '成立',\n",
       " '建',\n",
       " '性',\n",
       " '亦',\n",
       " '成',\n",
       " '监视',\n",
       " '式',\n",
       " '赛',\n",
       " '因此',\n",
       " '之一',\n",
       " '长',\n",
       " '中的',\n",
       " '从',\n",
       " '代表',\n",
       " '那',\n",
       " '全',\n",
       " '公里',\n",
       " '海',\n",
       " '如',\n",
       " '化',\n",
       " '首',\n",
       " 'x',\n",
       " '位于',\n",
       " '瓦',\n",
       " '版',\n",
       " '国家',\n",
       " 'in',\n",
       " '起',\n",
       " '要',\n",
       " '原',\n",
       " '年代',\n",
       " '工作',\n",
       " '北',\n",
       " '政治',\n",
       " 'w',\n",
       " '级',\n",
       " '星',\n",
       " '她',\n",
       " 'left',\n",
       " '作',\n",
       " '内',\n",
       " '使',\n",
       " '面积',\n",
       " '指',\n",
       " '面',\n",
       " '万',\n",
       " '作品',\n",
       " '把',\n",
       " '入',\n",
       " '线',\n",
       " '河',\n",
       " '文化',\n",
       " '座',\n",
       " '氏',\n",
       " '更',\n",
       " '曼',\n",
       " '能',\n",
       " '张',\n",
       " '维',\n",
       " 't',\n",
       " '季',\n",
       " '哈',\n",
       " '女',\n",
       " '行政',\n",
       " '局',\n",
       " '恩',\n",
       " '地区',\n",
       " '正式',\n",
       " '外',\n",
       " '明',\n",
       " '美',\n",
       " '字',\n",
       " '即',\n",
       " '北京',\n",
       " '不同',\n",
       " '行',\n",
       " '也是',\n",
       " '它',\n",
       " '足球',\n",
       " '表示',\n",
       " '塞',\n",
       " '目前',\n",
       " '同',\n",
       " '所有',\n",
       " '种',\n",
       " '开始',\n",
       " 'n',\n",
       " '来',\n",
       " '部分',\n",
       " '中央',\n",
       " '森',\n",
       " '国',\n",
       " '球',\n",
       " '古',\n",
       " '生',\n",
       " '亚',\n",
       " '但是',\n",
       " '再',\n",
       " '党',\n",
       " '纳',\n",
       " '非',\n",
       " '没有',\n",
       " 'h',\n",
       " '乡',\n",
       " '奥',\n",
       " '街',\n",
       " '提供',\n",
       " '城市',\n",
       " '一些',\n",
       " '！',\n",
       " '士',\n",
       " '成为',\n",
       " '系统',\n",
       " '&',\n",
       " 'www',\n",
       " '水',\n",
       " '人物',\n",
       " '加入',\n",
       " '英',\n",
       " '如果',\n",
       " '上海',\n",
       " '进行',\n",
       " '史',\n",
       " '第三',\n",
       " '波',\n",
       " '委员',\n",
       " '事',\n",
       " '达',\n",
       " '共',\n",
       " '回',\n",
       " 'r',\n",
       " '场',\n",
       " '吉',\n",
       " '支持',\n",
       " '你',\n",
       " 'g',\n",
       " '方',\n",
       " '属',\n",
       " '学院',\n",
       " '今',\n",
       " '周',\n",
       " '石',\n",
       " '事件',\n",
       " '建立',\n",
       " '生活',\n",
       " 'to',\n",
       " 'i',\n",
       " '派',\n",
       " '教育',\n",
       " '正',\n",
       " '由于',\n",
       " '桥',\n",
       " '还',\n",
       " '未',\n",
       " '铁路',\n",
       " '改',\n",
       " '法国',\n",
       " '称',\n",
       " '系',\n",
       " '百科',\n",
       " '完成',\n",
       " '白',\n",
       " '员',\n",
       " '得',\n",
       " '副',\n",
       " '沙',\n",
       " '托',\n",
       " '…',\n",
       " '约',\n",
       " '龙',\n",
       " '诺',\n",
       " '可能',\n",
       " 'k',\n",
       " '单位',\n",
       " '这个',\n",
       " '官',\n",
       " '梅',\n",
       " '队',\n",
       " '中文',\n",
       " '自由',\n",
       " '各',\n",
       " '联',\n",
       " '社',\n",
       " '光',\n",
       " '重要',\n",
       " '均',\n",
       " '工程',\n",
       " '港',\n",
       " '代',\n",
       " '所以',\n",
       " '列',\n",
       " '公',\n",
       " '段',\n",
       " '提交',\n",
       " '车',\n",
       " '每',\n",
       " '学',\n",
       " '一般',\n",
       " '才',\n",
       " 'v',\n",
       " '中华',\n",
       " '需要',\n",
       " '机',\n",
       " '江',\n",
       " '^',\n",
       " '获得',\n",
       " '提',\n",
       " '莫',\n",
       " '他们',\n",
       " '兰',\n",
       " '国际',\n",
       " '就是',\n",
       " '博',\n",
       " '／',\n",
       " 'o',\n",
       " '最佳',\n",
       " '门',\n",
       " '通过',\n",
       " '泰',\n",
       " '地方',\n",
       " '系列',\n",
       " '则',\n",
       " '登',\n",
       " '黑',\n",
       " '说',\n",
       " '希',\n",
       " '器',\n",
       " '花',\n",
       " '神',\n",
       " '宗',\n",
       " 'l',\n",
       " '共和国',\n",
       " '清',\n",
       " '最高',\n",
       " '要求',\n",
       " '受',\n",
       " '语',\n",
       " '』',\n",
       " '全国',\n",
       " '处',\n",
       " '『',\n",
       " '影响',\n",
       " '版本',\n",
       " '刘',\n",
       " '只有',\n",
       " '合',\n",
       " '最大',\n",
       " '院',\n",
       " '立',\n",
       " '出生',\n",
       " '朱',\n",
       " '另外',\n",
       " '华',\n",
       " '电影',\n",
       " '航空',\n",
       " '出版',\n",
       " '成功',\n",
       " '堂',\n",
       " '期',\n",
       " '点',\n",
       " 'u',\n",
       " '认为',\n",
       " '力',\n",
       " '班',\n",
       " '属于',\n",
       " '作为',\n",
       " '民',\n",
       " '→',\n",
       " '康',\n",
       " '福',\n",
       " '菲',\n",
       " '图',\n",
       " '海拔',\n",
       " '杜',\n",
       " '>',\n",
       " '方式',\n",
       " '且',\n",
       " '世纪',\n",
       " '率',\n",
       " '很',\n",
       " '官方',\n",
       " '历史',\n",
       " '师',\n",
       " '得到',\n",
       " '陈',\n",
       " '去',\n",
       " '平',\n",
       " '计划',\n",
       " '理',\n",
       " '建筑',\n",
       " '页',\n",
       " '印度',\n",
       " '街道',\n",
       " '都是',\n",
       " '存在',\n",
       " '德国',\n",
       " '令',\n",
       " '圣',\n",
       " '之后',\n",
       " '时间',\n",
       " '编辑',\n",
       " '卡特',\n",
       " '群',\n",
       " '黄',\n",
       " '命名',\n",
       " '英文',\n",
       " '曲',\n",
       " '瑞',\n",
       " '馆',\n",
       " '保护',\n",
       " '内容',\n",
       " '游戏',\n",
       " '任何',\n",
       " '运动',\n",
       " '唐',\n",
       " '西班牙',\n",
       " '受到',\n",
       " '甲',\n",
       " '经济',\n",
       " '世',\n",
       " '问题',\n",
       " '不是',\n",
       " 'php',\n",
       " '超',\n",
       " '丁',\n",
       " '夏',\n",
       " '萨',\n",
       " '权',\n",
       " '以上',\n",
       " '著名',\n",
       " 'for',\n",
       " '仍',\n",
       " '发现',\n",
       " '因为',\n",
       " '志',\n",
       " '制',\n",
       " '网',\n",
       " '梁',\n",
       " '胡',\n",
       " '角色',\n",
       " '奖',\n",
       " '武',\n",
       " '大陆',\n",
       " '给',\n",
       " 'right',\n",
       " '学校',\n",
       " '组织',\n",
       " '半',\n",
       " '商',\n",
       " 'color',\n",
       " '女性',\n",
       " '方面',\n",
       " '高度',\n",
       " '电视',\n",
       " '治',\n",
       " '男',\n",
       " '英国',\n",
       " '之前',\n",
       " '合作',\n",
       " '往',\n",
       " '杨',\n",
       " '岛',\n",
       " '具有',\n",
       " '卷',\n",
       " '位置',\n",
       " '通',\n",
       " '取得',\n",
       " 'on',\n",
       " '定',\n",
       " '造成',\n",
       " '只',\n",
       " '发展',\n",
       " '歌曲',\n",
       " '已经',\n",
       " '一次',\n",
       " '若',\n",
       " '初',\n",
       " '植物',\n",
       " '封',\n",
       " 'by',\n",
       " '皮',\n",
       " '非常',\n",
       " '而且',\n",
       " '设计',\n",
       " '组',\n",
       " '主义',\n",
       " '间',\n",
       " '同时',\n",
       " '无',\n",
       " '通常',\n",
       " '形成',\n",
       " '头',\n",
       " '九',\n",
       " '乐',\n",
       " '完全',\n",
       " '着',\n",
       " '信',\n",
       " '过',\n",
       " '接受',\n",
       " '交通',\n",
       " '木',\n",
       " '团',\n",
       " '便',\n",
       " '社会',\n",
       " '片',\n",
       " '室',\n",
       " '故事',\n",
       " '直接',\n",
       " '湖',\n",
       " '参加',\n",
       " '根',\n",
       " '保留',\n",
       " '技术',\n",
       " '希望',\n",
       " '红',\n",
       " '手',\n",
       " '心',\n",
       " '巴士',\n",
       " '播放',\n",
       " '音',\n",
       " '增加',\n",
       " '角',\n",
       " '耶',\n",
       " '楼',\n",
       " '何',\n",
       " '丹',\n",
       " '太',\n",
       " '这些',\n",
       " '书',\n",
       " '徐',\n",
       " '永',\n",
       " '歌',\n",
       " '美元',\n",
       " '战',\n",
       " '霍',\n",
       " '先',\n",
       " '讨论',\n",
       " '沟',\n",
       " '投票',\n",
       " '查',\n",
       " '数',\n",
       " '苏',\n",
       " '民主',\n",
       " '当时',\n",
       " '寺',\n",
       " '控制',\n",
       " '蒙',\n",
       " '删除',\n",
       " '根据',\n",
       " '以下',\n",
       " '然而',\n",
       " '七',\n",
       " '口',\n",
       " '仁',\n",
       " '重新',\n",
       " '景',\n",
       " '反',\n",
       " '推出',\n",
       " '追踪',\n",
       " '隆',\n",
       " '青',\n",
       " '发',\n",
       " '不能',\n",
       " '播出',\n",
       " '年度',\n",
       " '雅',\n",
       " 'https',\n",
       " '宋',\n",
       " '一直',\n",
       " '岁',\n",
       " '附近',\n",
       " '形',\n",
       " '意大利',\n",
       " '歌手',\n",
       " '宣布',\n",
       " '店',\n",
       " '大量',\n",
       " '做',\n",
       " '二十',\n",
       " '相',\n",
       " '开',\n",
       " '司',\n",
       " '至今',\n",
       " '好',\n",
       " '教授',\n",
       " '很多',\n",
       " '让',\n",
       " '双',\n",
       " '经',\n",
       " '源',\n",
       " '八',\n",
       " '〉',\n",
       " '演出',\n",
       " '当',\n",
       " '除了',\n",
       " '文字',\n",
       " '民族',\n",
       " '〈',\n",
       " '主席',\n",
       " '届',\n",
       " '文物',\n",
       " '老',\n",
       " '女子',\n",
       " '交',\n",
       " '真',\n",
       " '叶',\n",
       " '票',\n",
       " '族',\n",
       " '打',\n",
       " '能力',\n",
       " '佛',\n",
       " '少',\n",
       " '模板',\n",
       " '战争',\n",
       " '称为',\n",
       " '帝',\n",
       " '您',\n",
       " '模式',\n",
       " '库',\n",
       " '发生',\n",
       " '常',\n",
       " '方向',\n",
       " '郭',\n",
       " '始',\n",
       " 'z',\n",
       " '思',\n",
       " '方法',\n",
       " '出现',\n",
       " '阳',\n",
       " '播',\n",
       " '第四',\n",
       " '秀',\n",
       " '兼',\n",
       " '时期',\n",
       " '死',\n",
       " '界',\n",
       " '甚至',\n",
       " 'talk',\n",
       " '联合',\n",
       " '科学',\n",
       " '田',\n",
       " '用户',\n",
       " '只是',\n",
       " '巴西',\n",
       " '校',\n",
       " '乌',\n",
       " '汉',\n",
       " '共同',\n",
       " '出版社',\n",
       " '朝',\n",
       " '加上',\n",
       " '食',\n",
       " '杰',\n",
       " 'is',\n",
       " '体',\n",
       " '支',\n",
       " '哥',\n",
       " '像',\n",
       " '居民',\n",
       " '传',\n",
       " '功能',\n",
       " 'from',\n",
       " '利用',\n",
       " '平均',\n",
       " '侵',\n",
       " '再次',\n",
       " '铁',\n",
       " '故',\n",
       " '之间',\n",
       " '量',\n",
       " '确定',\n",
       " '全球',\n",
       " '全部',\n",
       " '音乐',\n",
       " '藏',\n",
       " '中共',\n",
       " '毛',\n",
       " 'y',\n",
       " '川',\n",
       " '案',\n",
       " '草',\n",
       " 'at',\n",
       " '宁',\n",
       " '名字',\n",
       " '篇',\n",
       " '地球',\n",
       " '期间',\n",
       " '贝',\n",
       " '京',\n",
       " '君',\n",
       " '是否',\n",
       " '部份',\n",
       " '赵',\n",
       " '死亡',\n",
       " '进入',\n",
       " '溪',\n",
       " '分类',\n",
       " '跟',\n",
       " '或者',\n",
       " '唱片',\n",
       " '安全',\n",
       " '玉',\n",
       " '豪',\n",
       " '唯一',\n",
       " '原因',\n",
       " '管',\n",
       " '辛',\n",
       " '法律',\n",
       " '革命',\n",
       " '请',\n",
       " '男性',\n",
       " '目的',\n",
       " '章',\n",
       " '形式',\n",
       " '设',\n",
       " '报告',\n",
       " '置',\n",
       " '吧',\n",
       " '基本',\n",
       " '蔡',\n",
       " '清朝',\n",
       " '客',\n",
       " '修',\n",
       " '科技',\n",
       " '青年',\n",
       " '流',\n",
       " '赤',\n",
       " '蒙古',\n",
       " '后来',\n",
       " '类',\n",
       " '语言',\n",
       " '教',\n",
       " '解放',\n",
       " '左',\n",
       " '戴',\n",
       " '自然',\n",
       " '台北',\n",
       " '列车',\n",
       " '欧洲',\n",
       " '新的',\n",
       " '庙',\n",
       " '活动',\n",
       " '主持',\n",
       " '切',\n",
       " '一起',\n",
       " '吴',\n",
       " '服务',\n",
       " '越南',\n",
       " '三年',\n",
       " 'stadium',\n",
       " '接',\n",
       " '卢',\n",
       " '剧',\n",
       " '快速',\n",
       " '百',\n",
       " '相同',\n",
       " '兵',\n",
       " '来源',\n",
       " '依',\n",
       " '×',\n",
       " '开发',\n",
       " '松',\n",
       " '这种',\n",
       " '亿',\n",
       " '政策',\n",
       " '日期',\n",
       " '出身',\n",
       " '具',\n",
       " '一部',\n",
       " '较',\n",
       " '居',\n",
       " '物',\n",
       " '现在',\n",
       " '普通',\n",
       " '男子',\n",
       " '理由',\n",
       " '信息',\n",
       " '云',\n",
       " '书记',\n",
       " '最终',\n",
       " '南京',\n",
       " '交流',\n",
       " '最后',\n",
       " '独立',\n",
       " '费',\n",
       " '款',\n",
       " '艺术',\n",
       " '条',\n",
       " '保',\n",
       " '我们',\n",
       " '排名',\n",
       " '表',\n",
       " '素',\n",
       " '政',\n",
       " '集团',\n",
       " '余',\n",
       " '一部分',\n",
       " '许多',\n",
       " '考',\n",
       " '园',\n",
       " '桑',\n",
       " '博士',\n",
       " '在此',\n",
       " '立法',\n",
       " '尾',\n",
       " '卫',\n",
       " '足',\n",
       " '架',\n",
       " '人士',\n",
       " '比赛',\n",
       " '短',\n",
       " '坑',\n",
       " '大型',\n",
       " '庄',\n",
       " '毕业',\n",
       " '进',\n",
       " '一年',\n",
       " '柯',\n",
       " '生物',\n",
       " '春',\n",
       " '公共',\n",
       " '仅',\n",
       " '取',\n",
       " '公路',\n",
       " '冠',\n",
       " '拿',\n",
       " '标准',\n",
       " '作家',\n",
       " '密',\n",
       " '哪',\n",
       " '扎',\n",
       " '空',\n",
       " '雪',\n",
       " '兴',\n",
       " '牛',\n",
       " '总统',\n",
       " '知',\n",
       " '生产',\n",
       " '情况',\n",
       " '火',\n",
       " '单',\n",
       " '广东',\n",
       " '广',\n",
       " '值',\n",
       " 'no',\n",
       " '十二',\n",
       " '占',\n",
       " 'with',\n",
       " '新加坡',\n",
       " '西部',\n",
       " '土',\n",
       " '早期',\n",
       " '并且',\n",
       " '另',\n",
       " '速度',\n",
       " '增',\n",
       " '道路',\n",
       " '到了',\n",
       " '节',\n",
       " '低',\n",
       " '色',\n",
       " '母',\n",
       " '仍然',\n",
       " '配音',\n",
       " '每年',\n",
       " '建设',\n",
       " '天津',\n",
       " '我的',\n",
       " '主任',\n",
       " '领导',\n",
       " '决定',\n",
       " '广州',\n",
       " '富',\n",
       " '千',\n",
       " '带',\n",
       " '会议',\n",
       " '去世',\n",
       " '大部分',\n",
       " '学生',\n",
       " '为了',\n",
       " '房',\n",
       " '关系',\n",
       " '昭和',\n",
       " '最早',\n",
       " '太平洋',\n",
       " '除',\n",
       " '意',\n",
       " '皆',\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_albpe2.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_rnn_hlat.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/bpe_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cnnencdec.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/chinese_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/data/wordlevel/test.40000.response\n",
      "[[0.927494562005274, 0.911279578013704, 0.9193949321176036, 0.8979669873971013, 0.6834743519640487, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# 计算一个文件的embedding\n",
    "random_embedding = dict()\n",
    "\n",
    "def get_embeddings(file,subword=None):\n",
    "    embeddings = []\n",
    "    valids = []\n",
    "    count = 0\n",
    "    with open(file, encoding='utf-8') as fin:\n",
    "        for line in fin.readlines():\n",
    "            encoded_line = encode(line,subword)\n",
    "            tmp = np.zeros([300])\n",
    "            count = 0\n",
    "            for word in encoded_line.split(' '):\n",
    "                if word in vectors[0]:\n",
    "                    tmp += vectors[0][word]\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if word in random_embedding:\n",
    "                        noisy = random_embedding[word]\n",
    "                    else:  \n",
    "                        noisy = np.random.normal(size=[300])\n",
    "                        #noisy = noisy/sum(np.sqrt(noisy*noisy))\n",
    "                        random_embedding[word] = noisy\n",
    "                    tmp+=noisy\n",
    "                    count += 1\n",
    "            if count > 0:\n",
    "                tmp = tmp / sum(np.sqrt(tmp*tmp))\n",
    "                valids.append(1)\n",
    "            else:\n",
    "                valids.append(0)\n",
    "            embeddings.append(tmp)\n",
    "        return embeddings,valids\n",
    "ref_embeddings  = get_embeddings(ref_file,None)\n",
    "def distances(embedA,embedB,validA,validB):\n",
    "    res = []\n",
    "    \n",
    "    for a,b,c,d in zip(embedA,embedB,validA,validB):\n",
    "        if c*d == 0:\n",
    "            print('error')\n",
    "        dis = (sum(a*b)+1e-10) / (np.sqrt(sum(a*a))* np.sqrt(sum(b*b))+1e-10)\n",
    "        res.append(dis)\n",
    "        \n",
    "    return sum(res) / len(res)\n",
    "embeddings = []\n",
    "final_names = eval_files + [ref_file]\n",
    "valids = []\n",
    "for file,subword in zip(eval_files + [ref_file], eval_subword +[None]):\n",
    "    print(file)\n",
    "    embedding,valid = get_embeddings(file,subword)\n",
    "    embeddings.append(embedding)\n",
    "    valids.append(valid)\n",
    "\n",
    "matrix = []\n",
    "for i in range(len(embeddings)-1,len(embeddings)):\n",
    "    row = []\n",
    "    for j in range(0,len(embeddings)):\n",
    "        diss = distances(embeddings[i],embeddings[j],valids[i],valids[j])\n",
    "        row.append(diss)\n",
    "    matrix.append(row)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_albpe2.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_rnn_hlat.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/bpe_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cnnencdec.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/chinese_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/data/wordlevel/test.40000.response\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-f0ebeb7eb611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mdiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-f0ebeb7eb611>\u001b[0m in \u001b[0;36mdistances\u001b[0;34m(embedA, embedB, validA, validB)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 计算一个文件的embedding Gready\n",
    "def get_embeddings(file,subword=None):\n",
    "    embeddings = []\n",
    "    valids = []\n",
    "    count = 0\n",
    "    with open(file, encoding='utf-8') as fin:\n",
    "        for line in fin.readlines():\n",
    "            encoded_line = encode(line,subword)\n",
    "            tmp = []\n",
    "            count = 0\n",
    "            for word in encoded_line.split(' '):\n",
    "                if word in vectors[0]:\n",
    "                    tmp.append(vectors[0][word])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    noisy = np.random.uniform(size=[300])\n",
    "                    noisy = noisy/sum(np.sqrt(noisy*noisy))\n",
    "                    tmp.append(noisy)\n",
    "                    count += 1\n",
    "            if count > 0:\n",
    "                valids.append(1)\n",
    "            else:\n",
    "                valids.append(0)\n",
    "            embeddings.append(tmp)\n",
    "        return embeddings,valids\n",
    "ref_embeddings  = get_embeddings(ref_file,None)\n",
    "\n",
    "def distances(embedA,embedB,validA,validB):\n",
    "    res = []\n",
    "    \n",
    "    for a,b,c,d in zip(embedA,embedB,validA,validB):\n",
    "        if c*d == 0:\n",
    "            print('error')\n",
    "        for r in a:\n",
    "            score1 = -1\n",
    "            for r1 in b:\n",
    "                dis = (sum(r*r1)+1e-10) / (np.sqrt(sum(r*r))* np.sqrt(sum(r1*r1))+1e-10)\n",
    "                score1 = max(dis,score1)\n",
    "        for r in b:\n",
    "            score2 = -1\n",
    "            for r1 in a:\n",
    "                dis = (sum(r*r1)+1e-10) / (np.sqrt(sum(r*r))* np.sqrt(sum(r1*r1))+1e-10)\n",
    "                score2 = max(dis,score2)\n",
    "        res.append(score1+score2)\n",
    "        \n",
    "    return sum(res) / len(res) / 2\n",
    "embeddings = []\n",
    "final_names = eval_files + [ref_file]\n",
    "valids = []\n",
    "for file,subword in zip(eval_files + [ref_file], eval_subword +[None]):\n",
    "    print(file)\n",
    "    embedding,valid = get_embeddings(file,subword)\n",
    "    embeddings.append(embedding)\n",
    "    valids.append(valid)\n",
    "\n",
    "matrix = []\n",
    "for i in range(len(embeddings)-1,len(embeddings)):\n",
    "    row = []\n",
    "    for j in range(0,len(embeddings)):\n",
    "        diss = distances(embeddings[i],embeddings[j],valids[i],valids[j])\n",
    "        row.append(diss)\n",
    "    matrix.append(row)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_albpe2.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cn_rnn_hlat.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/bpe_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/cnnencdec.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/infer_test/chinese_lstm.test.txt\n",
      "/ldev/tensorflow/nmt2/nmt/data/wordlevel/test.40000.response\n",
      "[[0.5710198406937087, 0.5525693729637218, 0.5578741953815899, 0.5658481167931326, 0.3565961653136164, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999999999998, 0.9999999999999998, 0.9999999999999998, 1.0, 0.9999999999999998]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
