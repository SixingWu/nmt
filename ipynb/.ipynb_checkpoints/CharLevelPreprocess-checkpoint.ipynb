{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 4435959\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "len_counter = defaultdict(int)\n",
    "\n",
    "in_path = '/ldev/tensorflow/seq2seq/rawdata/DiaTest/'\n",
    "\n",
    "message_path = in_path + 'huaweiFull.message'\n",
    "response_path = in_path + 'huaweiFull.response'\n",
    "\n",
    "messages = []\n",
    "responses = []\n",
    "with open(message_path,'r+',encoding='utf-8') as fin:\n",
    "    lines = fin.readlines()\n",
    "    messages = [line.strip('\\n') for line in lines]\n",
    "    for line in messages:\n",
    "        len_counter[len(line)] += 1\n",
    "\n",
    "with open(response_path,'r+',encoding='utf-8') as fin:\n",
    "    lines = fin.readlines()\n",
    "    responses = [line.strip('\\n') for line in lines]\n",
    "    for line in responses:\n",
    "        len_counter[len(line)] += 1\n",
    "\n",
    "assert len(messages) == len(responses)\n",
    "\n",
    "print('total lines: %d' % (len(messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['看到 榜样 的 力量 ， 大家 心里 会 更 安心',\n",
       " '某 前锋 完全 没有 预判 跑位 ， 速度 还 没有 对手 后卫 转身 加 回 追 速度快',\n",
       " '它 这 是 间接 暗示 你 ， 不如 搂 在一起 睡 会儿 吧',\n",
       " 'I want to go to Yunnan province in 2013 .',\n",
       " '如果 雍正 那会儿 有 QQ ， 那 《 甄嬛传 》 里边 的 人 … …',\n",
       " '这个 是 日本 的 那个 什么 组合么',\n",
       " '位置 是 创意 的 根源 ， 二师兄 ， 哈哈 。',\n",
       " '我 爱上 了 一 匹 汗 血 宝马 ， 可是 我 没有 马场 也 没有 钱 。',\n",
       " '这个 。 掉 节操 的 问句 ， 床上 咋办 。',\n",
       " '要么 带 套 ， 要么 大 肚 。']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看到 榜样 的 力量 ， 大家 心里 会 更 安心\n",
      "看到 榜样 的 力量 ， 大家 心里 会 更 安心#\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def filter(text):\n",
    "    res = re.sub(r'#[\\S ]*#',\"\", text)\n",
    "    res = re.sub(r'（[\\S ]+）',\"\", text)\n",
    "    res = re.sub(r'alink',\"\", res)\n",
    "    res = re.sub(r'[ ]+',\" \", res)\n",
    "    return res.strip()\n",
    "\n",
    "\n",
    "for line in responses[1000:1001]:\n",
    "    print(line)\n",
    "    print(filter(line) + '#') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 3788600\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "new_messages = []\n",
    "new_responses = []\n",
    "msg_counter = defaultdict(int)\n",
    "res_counter = defaultdict(int)\n",
    "str_counter = defaultdict(int)\n",
    "for msg,res in zip(messages,responses):\n",
    "    if msg == res:\n",
    "        continue\n",
    "    fmsg = filter(msg)\n",
    "    fres = filter(res)\n",
    "    vt = fmsg +'alink' + fres\n",
    "    if msg_counter[fmsg] > 75 or res_counter[fres] > 75 or str_counter[vt] > 20 :\n",
    "        continue\n",
    "    if fmsg == fres:\n",
    "        continue\n",
    "    msg_counter[fmsg] += 1\n",
    "    res_counter[fres]  += 1\n",
    "    str_counter[vt] += 1\n",
    "    \n",
    "    nmsg = ' '.join( x for x in fmsg.split())\n",
    "    nres = ' '.join( x for x in fres.split())\n",
    "    fmsg = fmsg.split()\n",
    "    fres = fres.split()\n",
    "    if len(fmsg) < 2 or len(fres) < 2 or len(fmsg) > 20 or len(fres) > 20:\n",
    "        continue\n",
    "    new_messages.append(nmsg.split())\n",
    "    new_responses.append(nres.split())\n",
    "print('total lines: %d' % (len(new_messages))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_messages = []\n",
    "seg_responses = []\n",
    "for line in new_messages:\n",
    "    segs = []\n",
    "    for item in line:\n",
    "        if item == '@@':\n",
    "            segs.append(item)\n",
    "        else:\n",
    "            segs = segs + list(item)\n",
    "    seg_messages.append(segs)\n",
    "\n",
    "for line in new_responses:\n",
    "    segs = []\n",
    "    for item in line:\n",
    "        if item == '@@':\n",
    "            segs.append(item)\n",
    "        else:\n",
    "            segs = segs + list(item)\n",
    "    seg_responses.append(segs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['中', '国', '@@', '移', '动', '@@', '营', '销', '@@', '行', '来', '@@', '发', '展', '@@', '报', '告', '@@'], ['小', '马', '@@', '也', '@@', '疯', '狂', '@@', '-', '-', '-', '-', '-', '-', '@@', '地', '位', '@@', '之', '@@', '争', '@@', '。', '@@'], ['那', '些', '@@', '年', '@@', '，', '@@', '我', '们', '@@', '一', '起', '@@', '偷', '看', '@@', '过', '@@', '的', '@@', '电', '视', '@@', '。', '@@', '「', '@@', '暴', '@@', '走', '@@', '漫', '画', '@@', '」', '@@'], ['北', '京', '@@', '的', '@@', '小', '@@', '纯', '洁', '们', '@@', '，', '@@', '周', '日', '见', '@@', '。', '@@', '#', '@@', '硬', '汉', '@@', '摆', '@@', '拍', '@@', '清', '纯', '@@', '照', '@@', '#', '@@'], ['要', '是', '@@', '这', '@@', '一', '@@', '年', '@@', '哭', '泣', '@@', '的', '@@', '理', '由', '@@', '不', '@@', '再', '@@', '是', '@@', '难', '过', '@@', '而', '@@', '是', '@@', '感', '动', '@@', '会', '@@', '多', '么', '@@', '好', '@@'], ['对', '于', '@@', '国', '内', '@@', '动', '漫', '@@', '画', '作', '者', '@@', '引', '用', '@@', '工', '笔', '@@', '素', '材', '@@', '的', '@@', '一', '些', '@@', '个', '人', '@@', '意', '见', '@@', '。', '@@'], ['猫', '咪', '@@', '保', '镖', '@@', '最', '@@', '赞', '@@', '了', '@@', '！', '@@', '你', '们', '@@', '看', '懂', '@@', '了', '@@', '吗', '@@', '？', '@@', '！', '@@'], ['莫', '愁', '@@', '和', '@@', '所', '有', '@@', '人', '@@', '开', '@@', '了', '@@', '一', '@@', '个', '@@', '玩', '笑', '@@', '—', '—', '@@', '其', '实', '@@', '，', '@@', '她', '@@', '是', '@@', '会', '@@', '正', '常', '@@', '唱', '歌', '@@', '的', '@@', '…', '@@', '…', '@@'], ['你', '@@', '见', '@@', '过', '@@', '皮', '卡', '丘', '@@', '喝', '水', '@@', '的', '@@', '样', '子', '@@', '吗', '@@', '？', '@@'], ['如', '果', '@@', '有', '@@', '个', '@@', '人', '@@', '能', '@@', '让', '@@', '你', '@@', '忘', '掉', '@@', '过', '去', '@@', '，', '@@', '那', 'T', 'A', '@@', '很', '@@', '可', '能', '@@', '就', '是', '@@', '你', '@@', '的', '@@', '未', '来', '@@', '。', '@@'], ['我', '@@', '在', '@@', '北', '京', '@@', '，', '@@', '2', '4', '@@', '岁', '@@', '，', '@@', '想', '@@', '去', '@@', '马', '尔', '代', '夫', '@@', '，', '@@', '一', '@@', '个', '@@', '人', '@@', '。', '@@'], ['哥', '@@', '你', '@@', '还', '@@', '跳', '@@', '不', '@@', '跳', '楼', '@@', '了', '@@', '？', '@@', '我', '们', '@@', '要', '@@', '下', '班', '@@', '啊', '@@', '！', '@@'], ['龙', '@@', '生', '@@', '龙', '@@', '，', '@@', '凤', '@@', '生', '@@', '凤', '@@', '，', '@@', '是', '@@', '个', '@@', '喵', '咪', '@@', '它', '@@', '就', '萌', '@@', '。', '@@'], ['从', '@@', '胚', '胎', '@@', '期', '@@', '开', '始', '@@', '的', '@@', '面', '部', '@@', '特', '征', '@@', '演', '变', '@@', '过', '程', '@@'], ['本', '@@', '届', '@@', '轮', '值', '@@', '主', '席', '@@', '王', '石', '致', '@@', '开', '幕', '词', '@@', '。', '@@', '讲', '@@', '6', '0', '@@', '岁', '@@', '上', '@@', '哈', '佛', '@@', '。', '@@'], ['非', '常', '@@', '不', '@@', '喜', '欢', '@@', '北', '京', '@@', '现', '在', '@@', '的', '@@', '天', '气', '@@', '…', '@@', '…', '@@', '非', '常', '@@', '…', '@@', '…', '@@'], ['我', '@@', '第', '一', '@@', '次', '@@', '坐', '@@', '飞', '机', '@@', '是', '@@', '进', '@@', '安', '达', '@@', '信', '@@', '的', '@@', '入', '职', '@@', '培', '训', '@@', '，', '@@', '在', '@@', '深', '圳', '@@', '。', '@@', '你', '们', '@@', '哪', '@@', '？', '@@'], ['人', '生', '@@', '如', '@@', '戏', '@@', '，', '@@', '全', '@@', '靠', '@@', '演', '技', '@@', '。', '@@', '小', '@@', '受', '@@', '吓', '坏', '@@', '了', '@@', '。', '@@'], ['为', '什', '么', '@@', '这', '@@', '世', '上', '@@', '会', '@@', '有', '@@', '人', '@@', '以', '@@', '刁', '难', '@@', '他', '人', '@@', '为', '乐', '@@', '呢', '@@', '？', '@@'], ['算', '了', '@@', '算', '了', '@@', '，', '@@', '我', '@@', '看', '出', '来', '@@', '了', '@@', '，', '@@', '你', '们', '@@', '都', '@@', '想', '@@', '看', '@@', '男', '人', '@@', '！', '@@', '上', '@@', '张', '@@', '美', '@@', '男', '图', '@@', '。', '@@']]\n"
     ]
    }
   ],
   "source": [
    "print(seg_messages[0:20])\n",
    "new_messages = seg_messages\n",
    "new_responses = seg_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.00\n",
      "5 0.00\n",
      "6 0.00\n",
      "7 0.00\n",
      "8 0.00\n",
      "9 0.00\n",
      "10 0.00\n",
      "11 0.00\n",
      "12 0.00\n",
      "13 0.01\n",
      "14 0.02\n",
      "15 0.05\n",
      "16 0.08\n",
      "17 0.12\n",
      "18 0.16\n",
      "19 0.20\n",
      "20 0.24\n",
      "21 0.28\n",
      "22 0.32\n",
      "23 0.36\n",
      "24 0.40\n",
      "25 0.43\n",
      "26 0.47\n",
      "27 0.50\n",
      "28 0.53\n",
      "29 0.57\n",
      "30 0.60\n",
      "31 0.63\n",
      "32 0.66\n",
      "33 0.68\n",
      "34 0.71\n",
      "35 0.74\n",
      "36 0.76\n",
      "37 0.79\n",
      "38 0.81\n",
      "39 0.83\n",
      "40 0.85\n",
      "41 0.87\n",
      "42 0.89\n",
      "43 0.91\n",
      "44 0.93\n",
      "45 0.95\n",
      "46 0.96\n",
      "47 0.97\n",
      "48 0.98\n",
      "49 0.99\n",
      "50 0.99\n",
      "51 0.99\n",
      "52 0.99\n",
      "53 1.00\n",
      "54 1.00\n",
      "55 1.00\n",
      "56 1.00\n",
      "57 1.00\n",
      "58 1.00\n",
      "59 1.00\n",
      "60 1.00\n",
      "61 1.00\n",
      "62 1.00\n",
      "63 1.00\n",
      "64 1.00\n",
      "65 1.00\n",
      "66 1.00\n",
      "67 1.00\n",
      "68 1.00\n",
      "69 1.00\n",
      "70 1.00\n",
      "71 1.00\n",
      "72 1.00\n",
      "73 1.00\n",
      "74 1.00\n",
      "75 1.00\n",
      "76 1.00\n",
      "77 1.00\n",
      "78 1.00\n",
      "79 1.00\n",
      "80 1.00\n",
      "81 1.00\n",
      "82 1.00\n",
      "83 1.00\n",
      "84 1.00\n",
      "85 1.00\n",
      "86 1.00\n",
      "87 1.00\n",
      "88 1.00\n",
      "89 1.00\n",
      "90 1.00\n",
      "91 1.00\n",
      "92 1.00\n",
      "93 1.00\n",
      "94 1.00\n",
      "char_nums_per_word:\n",
      "1 0.60\n",
      "2 1.00\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "from collections import defaultdict\n",
    "len_counter = defaultdict(int)\n",
    "word_len_counter = defaultdict(int)\n",
    "num_of_words = 0\n",
    "tokenized_messages = new_messages\n",
    "tokenized_responses = new_responses\n",
    "for line in tokenized_messages + tokenized_responses:\n",
    "    len_counter[len(line)] += 1\n",
    "    num_of_words += len(line)\n",
    "    for item in line:\n",
    "        word_len_counter[len(item)] += 1\n",
    "\n",
    "sorted_length = sorted(len_counter.items(), key = lambda x:x[0])\n",
    "total_counter = 0\n",
    "for lens,counter in sorted_length:\n",
    "    total_counter += counter\n",
    "    print('%d %.2f' % (lens, total_counter/len(tokenized_messages)/2))\n",
    "\n",
    "print('char_nums_per_word:')\n",
    "sorted_length = sorted(word_len_counter.items(), key = lambda x:x[0])\n",
    "total_counter = 0\n",
    "for lens,counter in sorted_length:\n",
    "    total_counter += counter\n",
    "    print('%d %.2f' % (lens, total_counter/num_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = '/ldev/tensorflow/nmt2/nmt/data/charlevel/'\n",
    "import random\n",
    "random.seed(6666)\n",
    "\n",
    "total_num = len(messages)\n",
    "dev_num =  20000\n",
    "test_num = 20000\n",
    "max_len = 30\n",
    "train_num = total_num - dev_num - test_num\n",
    "\n",
    "random_orders = range(0, total_num)\n",
    "messages = tokenized_messages\n",
    "responses =  tokenized_responses\n",
    "file_map = {'message':tokenized_messages, 'response':tokenized_responses}\n",
    "for file_type in file_map.keys():\n",
    "    container = file_map[file_type]\n",
    "    with open(out_path + 'dev.'+file_type,'w+',encoding='utf-8') as fout:\n",
    "        for i in range(0,dev_num):\n",
    "            fout.write('%s\\n' % ' '.join(container[i][0:max_len]))\n",
    "    with open(out_path + 'test.'+file_type,'w+',encoding='utf-8') as fout:\n",
    "        for i in range(dev_num,test_num + test_num):\n",
    "            fout.write('%s\\n' % ' '.join(container[i][0:max_len]))\n",
    "    with open(out_path + 'train.'+file_type,'w+',encoding='utf-8') as fout:\n",
    "        for i in range(test_num + test_num,total_num):\n",
    "            fout.write('%s\\n' % ' '.join(container[i][0:max_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10578\n",
      "6454\n",
      "10432\n",
      "[('@@', 74374656), ('，', 4465533), ('的', 3570133), ('。', 2453947), ('是', 1868648), ('了', 1664973), ('！', 1549545), ('不', 1513748), ('一', 1507107), ('我', 1391889), ('这', 1284323), ('有', 1121473), ('你', 1034790), ('人', 1008785), ('个', 922307), ('好', 811696), ('？', 788476), ('么', 744060), ('在', 682849), ('看', 680794), ('大', 654280), ('就', 568476), ('来', 563755), ('天', 562714), ('啊', 511939), ('要', 509297), ('都', 502479), ('上', 482097), ('…', 467230), ('到', 450635), ('哈', 427835), ('#', 424641), ('还', 420579), ('们', 411434), ('小', 407226), ('子', 404008), ('没', 395831), ('会', 395541), ('中', 379125), ('时', 376055), ('真', 373024), ('说', 362481), ('得', 362299), ('可', 358574), ('最', 352106), ('国', 350013), ('也', 347501), ('生', 345962), ('过', 345892), ('想', 341862), ('家', 338301), ('能', 337590), ('年', 329064), ('很', 328329), ('下', 328023), ('多', 326722), ('那', 322476), ('为', 314639), ('0', 303290), ('样', 300296), ('心', 295874), ('1', 295306), ('以', 291348), ('爱', 289820), ('去', 288362), ('什', 279921), ('太', 278277), ('自', 272679), ('出', 260545), ('e', 256866), ('o', 256597), ('后', 254699), ('老', 254520), ('美', 249749), ('吧', 249565), ('：', 249537), ('发', 247666), ('2', 246783), ('点', 244182), ('和', 238661), ('i', 234457), ('里', 233566), ('今', 225571), ('吗', 224825), ('a', 223902), ('吃', 221282), ('开', 218666), ('图', 214038), ('用', 204992), ('现', 204971), ('起', 203877), ('【', 203283), ('道', 202310), ('只', 200207), ('日', 199026), ('如', 198542), ('对', 198299), ('喜', 197504), ('女', 196909), ('新', 196578)]\n"
     ]
    }
   ],
   "source": [
    "out_path = '/ldev/tensorflow/nmt2/nmt/data/charlevel/'\n",
    "in_path = '/ldev/tensorflow/nmt2/nmt/data/charlevel/'\n",
    "\n",
    "from collections import defaultdict\n",
    "counter = defaultdict(int)\n",
    "message_counter = defaultdict(int)\n",
    "response_counter = defaultdict(int)\n",
    "\n",
    "\n",
    "for file in ['message','response']:\n",
    "    with open(in_path + 'train.'+file,'r+',encoding='utf-8') as fin:\n",
    "        lines = fin.readlines()\n",
    "        container = message_counter\n",
    "        if file == 'response':\n",
    "            container = response_counter\n",
    "        for line in lines:\n",
    "            chars = line.strip('\\n').split(' ')\n",
    "            for char in chars:\n",
    "                if len(char) > 0:\n",
    "                    counter[char] += 1\n",
    "                    container[char] += 1\n",
    "\n",
    "sorted_counter = sorted(counter.items(), key = lambda x:x[1], reverse = True)\n",
    "sorted_message_counter = sorted(message_counter.items(), key = lambda x:x[1], reverse = True)\n",
    "sorted_response_counter = sorted(response_counter.items(), key = lambda x:x[1], reverse = True)\n",
    "print(len(sorted_counter))\n",
    "print(len(sorted_message_counter))\n",
    "print(len(sorted_response_counter))\n",
    "print(sorted_counter[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = '/ldev/tensorflow/nmt2/nmt/data/charlevel/'\n",
    "for file in ['message','response']:\n",
    "    with open(out_path + 'vocab.'+file,'w+',encoding='utf-8') as fout:\n",
    "        #fout.write('<UNK>\\n<S>\\n</S>\\n');\n",
    "        for item in sorted_counter:\n",
    "            fout.write(item[0]+'\\n')\n",
    "with open(out_path + 'vocab.'+'separate.response','w+',encoding='utf-8') as fout:\n",
    "        #fout.write('<UNK>\\n<S>\\n</S>\\n');\n",
    "        for item in sorted_response_counter:\n",
    "            fout.write(item[0]+'\\n')\n",
    "with open(out_path + 'vocab.'+'separate.message','w+',encoding='utf-8') as fout:\n",
    "        #fout.write('<unk>\\n<s>\\n</s>\\n');\n",
    "        for i,item in enumerate(sorted_message_counter):\n",
    "            if len(item[0]) == 0:\n",
    "                print('flag '+str(i))\n",
    "            fout.write(item[0]+'\\n')\n",
    "\n",
    "with open(out_path + 'vocab.'+'.counter','w+',encoding='utf-8') as fout:\n",
    "        fout.write('<unk>\\n\\t-1\\n<s>\\t-1\\n</s>\\t-1\\n');\n",
    "        for item in sorted_counter:\n",
    "            fout.write('%s\\t%d\\n'  % (item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sums = 0\n",
    "for i,(lens,counter) in enumerate(sorted_message_counter):\n",
    "    sums += counter\n",
    "print(len(sorted_message_counter))\n",
    "total_counter = 0\n",
    "for i,(lens,counter) in enumerate(sorted_message_counter):\n",
    "    total_counter += counter\n",
    "    if i%10000 == 0:\n",
    "        print('%d %.4f' % (i, total_counter/sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
