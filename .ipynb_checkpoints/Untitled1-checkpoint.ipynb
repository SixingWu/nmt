{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=1\n",
      "python3 -m nrm.nrm  --infer_beam_width=10 --out_dir=models/charlevel2 --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/charlevel2/vocab  --inference_input_file=/ldev/tensorflow/nmt2/nmt/data/charlevel2/dev.message  --inference_output_file=beam_search/char_raw_10_dev_f.inf.response >> beam_search/log/char_raw_10_dev_f.txt & \n",
      "export CUDA_VISIBLE_DEVICES=1\n",
      "python3 -m nrm.nrm  --infer_beam_width=10 --out_dir=models/charlevel2 --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/charlevel2/vocab  --inference_input_file=/ldev/tensorflow/nmt2/nmt/data/charlevel2/test.message  --inference_output_file=beam_search/char_raw_10_test_f.inf.response >> beam_search/log/char_raw_10_test_f.txt & \n"
     ]
    }
   ],
   "source": [
    "\n",
    "beam_sizes = [10]\n",
    "\n",
    "model_types = {\n",
    "#     'hybrid2W':'models/hybrid_2W',\n",
    "#     'hybrid4W':'models/hybrid_4W',\n",
    "#     'word_2W':'models/word_2W',\n",
    "#     'word_4W':'models/word_4W',\n",
    "    'DLF_hybrid_4W':'models/DLF_hybrid_4W',\n",
    "     'char_raw':'models/charlevel2',\n",
    "      'lfw_charcnn':'LFW_charCNN_hybrid_4W',\n",
    "#    'cl_hybrid_4W':  'models/cl_hybrid_4W',\n",
    "#    'cl_hybrid_2W':  'models/cl_hybrid_2W',\n",
    "#    'charCNN_hybrid_4W':'models/charCNN_hybrid_4W',\n",
    "#     'charCNN_hybrid_2W':'models/charCNN_hybrid_2W',\n",
    "#     'cnnEncDec' : 'models/cnnEncDecM2',\n",
    "#     'Subword2':'models/Subword2',\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "source = {\n",
    "    'hybrid2W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.20000.TYPE2',\n",
    "    'hybrid4W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.40000.TYPE2',\n",
    "    'word_2W':'/ldev/tensorflow/nmt2/nmt/data/wordlevel/TYPE1.20000.TYPE2',\n",
    "    'word_4W':'/ldev/tensorflow/nmt2/nmt/data/wordlevel/TYPE1.40000.TYPE2',\n",
    "    'char_raw':'/ldev/tensorflow/nmt2/nmt/data/charlevel2/TYPE1.TYPE2',\n",
    "    'cl_hybrid_2W': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.20000.TYPE2',\n",
    "    'cl_hybrid_4W': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.40000.TYPE2',\n",
    "    'charCNN_hybrid_4W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.40000.TYPE2',\n",
    "    'charCNN_hybrid_2W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.20000.TYPE2',\n",
    "    'lfw_charcnn':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.20000.TYPE2',\n",
    "    'DLF_hybrid_4W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/TYPE1.20000.TYPE2',\n",
    "    'cnnEncDec' :'/ldev/tensorflow/nmt2/nmt/data/charlevel2/TYPE1.TYPE2',\n",
    "     'Subword2':'/ldev/tensorflow/nmt2/nmt/data/Subword/TYPE1.TYPE2',\n",
    "}\n",
    "\n",
    "vocab_prefix = {\n",
    "    'hybrid2W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.20000',\n",
    "    'hybrid4W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.40000',\n",
    "    'word_2W':'/ldev/tensorflow/nmt2/nmt/data/wordlevel/vocab.20000',\n",
    "    'word_4W':'/ldev/tensorflow/nmt2/nmt/data/wordlevel/vocab.40000',\n",
    "    'char_raw':'/ldev/tensorflow/nmt2/nmt/data/charlevel2/vocab',\n",
    "    'cl_hybrid_2W': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.20000',\n",
    "    'cl_hybrid_4W': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.40000',\n",
    "    'lfw_charcnn': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.40000',\n",
    "    'DLF_hybrid_4W': '/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.40000',\n",
    "    'charCNN_hybrid_4W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.40000',\n",
    "    'charCNN_hybrid_2W':'/ldev/tensorflow/nmt2/nmt/data/hybrid2/vocab.20000',\n",
    "    'cnnEncDec' : '/ldev/tensorflow/nmt2/nmt/data/charlevel2/vocab',\n",
    "    'Subword2':'/ldev/tensorflow/nmt2/nmt/data/Subword/vocab.60000',\n",
    "}\n",
    "\n",
    "\n",
    "for beam_size in beam_sizes:\n",
    "    for task in model_types.keys():\n",
    "        for folder in ['']:\n",
    "            for test_file in ['dev','test']:\n",
    "                model_path = model_types[task]\n",
    "                input_file = source[task].replace('TYPE1',test_file).replace('.TYPE2','')\n",
    "                output_file = 'beam_search/%s_%d_%s_f%s' % (task,beam_size,test_file,folder.replace('/',''))\n",
    "                bash = 'python3 -m nrm.nrm '\n",
    "                bash += ' --infer_beam_width=%d' % beam_size\n",
    "                bash += ' --out_dir=%s ' % model_path\n",
    "                bash += ' --vocab_prefix=%s ' % vocab_prefix[task]\n",
    "                bash += ' --inference_input_file=%s.message ' % input_file\n",
    "                bash += ' --inference_output_file=%s.inf.response' % output_file\n",
    "                bash += ' >> beam_search/log/%s_%d_%s_f%s.txt & ' % (task,beam_size,test_file,folder.replace('/',''))\n",
    "\n",
    "                print('export CUDA_VISIBLE_DEVICES=1')\n",
    "                print(bash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
