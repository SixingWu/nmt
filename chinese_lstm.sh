python3 -m nrm.nrm      --embed_dim=512      --encoder_type=bi      --tgt=response      --src=message      --num_units=512      --steps_per_stats=100      --dev_prefix=/ldev/tensorflow/nmt2/nmt/data/wordlevel/dev      --batch_size=256      --unit_type=lstm      --share_vocab=False      --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/wordlevel/vocab.40000.separate      --out_dir=models/chinese_lstm      --metrics=rouge,bleu-1,bleu-2,bleu-3,bleu-4,distinct-1,distinct-2      --test_prefix=/ldev/tensorflow/nmt2/nmt/data/wordlevel/test      --tgt_max_len=20      --num_train_steps=1000000      --attention=luong      --infer_batch_size=10      --num_layers=2      --src_max_len=20      --train_prefix=/ldev/tensorflow/nmt2/nmt/data/wordlevel/train     >> logs/chinese_lstm.txt 

python3 -m nrm.nrm  --infer_beam_width=10 --out_dir=models/chinese_lstm --vocab_prefix=/ldev/tensorflow/nmt2/nmt/data/wordlevel/vocab.40000.separate --inference_input_file=/ldev/tensorflow/nmt2/nmt/data/wordlevel/test.message --inference_output_file=infer_test/chinese_lstm.test.txt >> infer_test/log/chinese_lstm.test.txt
    
python3 -m nrm.utils.evaluation_utils chinese_lstm /ldev/tensorflow/nmt2/nmt/data/wordlevel/test.response infer_test/chinese_lstm.test.txt infer_test/scores/chinese_lstm.test.txt rouge,bleu-1,bleu-2,bleu-3,bleu-4,distinct-1,distinct-2
    
